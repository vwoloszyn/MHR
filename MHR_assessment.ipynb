{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import make_scorer\n",
    "from time import time\n",
    "from sklearn import svm\n",
    "from sklearn import cross_validation\n",
    "\n",
    "import MHR as mhr\n",
    "\n",
    "def simple_spearman(x,y): return np.abs(spearmanr(x,y)[0])\n",
    "spearmanr_scorer = make_scorer(simple_spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def dcg_at_k(r, k, method=0):\n",
    "    \"\"\"Score is discounted cumulative gain (dcg)\n",
    "    Relevance is positive real values.  Can use binary\n",
    "    as the previous methods.\n",
    "    Example from\n",
    "    http://www.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf\n",
    "    >>> r = [3, 2, 3, 0, 0, 1, 2, 2, 3, 0]\n",
    "    >>> dcg_at_k(r, 1)\n",
    "    3.0\n",
    "    >>> dcg_at_k(r, 1, method=1)\n",
    "    3.0\n",
    "    >>> dcg_at_k(r, 2)\n",
    "    5.0\n",
    "    >>> dcg_at_k(r, 2, method=1)\n",
    "    4.2618595071429155\n",
    "    >>> dcg_at_k(r, 10)\n",
    "    9.6051177391888114\n",
    "    >>> dcg_at_k(r, 11)\n",
    "    9.6051177391888114\n",
    "    Args:\n",
    "        r: Relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "        k: Number of results to consider\n",
    "        method: If 0 then weights are [1.0, 1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "                If 1 then weights are [1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "    Returns:\n",
    "        Discounted cumulative gain\n",
    "    \"\"\"\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        if method == 0:\n",
    "            return r[0] + np.sum(r[1:] / np.log2(np.arange(2, r.size + 1)))\n",
    "        elif method == 1:\n",
    "            return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
    "        else:\n",
    "            raise ValueError('method must be 0 or 1.')\n",
    "    return 0.\n",
    "\n",
    "\n",
    "def ndcg_at_k(r, k, method=0):\n",
    "    \"\"\"Score is normalized discounted cumulative gain (ndcg)\n",
    "    Relevance is positive real values.  Can use binary\n",
    "    as the previous methods.\n",
    "    Example from\n",
    "    http://www.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf\n",
    "    >>> r = [3, 2, 3, 0, 0, 1, 2, 2, 3, 0]\n",
    "    >>> ndcg_at_k(r, 1)\n",
    "    1.0\n",
    "    >>> r = [2, 1, 2, 0]\n",
    "    >>> ndcg_at_k(r, 4)\n",
    "    0.9203032077642922\n",
    "    >>> ndcg_at_k(r, 4, method=1)\n",
    "    0.96519546960144276\n",
    "    >>> ndcg_at_k([0], 1)\n",
    "    0.0\n",
    "    >>> ndcg_at_k([1], 2)\n",
    "    1.0\n",
    "    Args:\n",
    "        r: Relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "        k: Number of results to consider\n",
    "        method: If 0 then weights are [1.0, 1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "                If 1 then weights are [1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "    Returns:\n",
    "        Normalized discounted cumulative gain\n",
    "    \"\"\"\n",
    "    dcg_max = dcg_at_k(sorted(r, reverse=True), k, method)\n",
    "    if not dcg_max:\n",
    "        return 0.\n",
    "    return dcg_at_k(r, k, method) / dcg_max\n",
    "\n",
    "\n",
    "def calc_ndcg(df, column,k):\n",
    "    min_votes=5\n",
    "    min_comments=30\n",
    "\n",
    "    ndcg_global=[]\n",
    "    grouped=df[df['tot'].astype(int)>min_votes].groupby('asin')\n",
    "\n",
    "    for name, group in grouped:\t\n",
    "        dffiltro = (df['asin']==name) & (df['tot'].astype(int)>min_votes) \n",
    "        comments_count = df[dffiltro ]['tot'].values\n",
    "        if ( (len(comments_count)>min_comments) ):\n",
    "            values_test = df[dffiltro]['helpfulness'].T.to_dict().values()\n",
    "            scores = df[dffiltro][column].T.to_dict().values()\n",
    "\n",
    "            \n",
    "            ind = (-np.array(scores)).argsort()\n",
    "            a = np.array(values_test)[ind]\t\n",
    "            ndcg = ndcg_at_k(a, k)\n",
    "            ndcg_global.append(ndcg)\n",
    "    return np.mean(ndcg_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19756, 19)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_features = pd.read_csv('data/eletronic_sample_counts.csv.gz')\n",
    "reviews_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Unnamed: 0', u'Unnamed: 0.1', u'asin', u'helpful', u'overall',\n",
       "       u'reviewText', u'reviewTime', u'reviewerID', u'reviewerName',\n",
       "       u'summary', u'unixReviewTime', u'helpfulness', u'tot', u'word_count',\n",
       "       u'sentence_count', u'unigram_count', u'pos_tag', u'adj', u'noun'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Unnamed: 0', u'Unnamed: 0.1', u'overall', u'unixReviewTime',\n",
       "       u'helpfulness', u'tot', u'word_count', u'sentence_count',\n",
       "       u'unigram_count', u'adj', u'noun'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_columns = reviews_features.select_dtypes(include=['float64','int','int64']).columns\n",
    "df_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11853\n",
      "fold=0 ndcg= 0.616566953143\n",
      "11853\n",
      "fold=1 ndcg= 0.644001272978\n",
      "11853\n",
      "fold=2 ndcg= 0.607666903717\n",
      "11853\n",
      "fold=3 ndcg= 0.655057569423\n",
      "11853\n",
      "fold=4 ndcg= 0.640695607425\n",
      "11853\n",
      "fold=5 ndcg= 0.620720575563\n",
      "11853\n",
      "fold=6 ndcg= 0.616819750379\n",
      "11853\n",
      "fold=7 ndcg= 0.596320987697\n",
      "11853\n",
      "fold=8 ndcg= 0.616838786607\n",
      "11853\n",
      "fold=9 ndcg= 0.616806797582\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVR(epsilon=0.001)\n",
    "\n",
    "\n",
    "rs = cross_validation.ShuffleSplit(len(reviews_features), n_iter=10, test_size=.4 , random_state=0)\n",
    "ind=0\n",
    "ndcg=[]\n",
    "for train_index, test_index in rs:\n",
    "    #train\n",
    "    features_train = reviews_features.ix[train_index][list(['word_count','sentence_count','unigram_count','adj','noun'])].values\n",
    "    labels_train = reviews_features.ix[train_index][\"helpfulness\"].values\n",
    "    clf.fit(features_train, labels_train)\n",
    "    \n",
    "    #test\n",
    "    features_test = reviews_features.ix[test_index][list(['word_count','sentence_count','unigram_count','adj','noun'])].values\n",
    "    labels_test = reviews_features.ix[test_index][\"helpfulness\"].values\n",
    "    x=clf.predict(features_test)\n",
    "    \n",
    "    dfTest= reviews_features.ix[test_index]\n",
    "    dfTest['svm']=x\n",
    "    local_ndcg = calc_ndcg(dfTest,'svm',5)\n",
    "    ndcg.append(local_ndcg)\n",
    "    print \"ndcg at fold \"+str(ind)+\" = \"+ str(local_ndcg)\n",
    "    \n",
    "    ind=ind+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 3\n",
      "7903\n",
      "0.569633838764\n",
      "0.580706391559\n",
      "0.637820846157\n",
      "0.585474216706\n",
      "0.627686360885\n",
      "0.639304985259\n",
      "0.633587411191\n",
      "0.609644088007\n",
      "0.674305980195\n",
      "0.637374826324\n",
      "0.573731185047\n",
      "0.650075542027\n",
      "0.629496477873\n",
      "0.645655689558\n",
      "0.596176575181\n",
      "0.663012699066\n",
      "0.64109822936\n",
      "0.66239608391\n",
      "0.62513974803\n",
      "0.651172930406\n",
      "0.592031922582\n",
      "0.623093598298\n",
      "0.570452588532\n",
      "0.594575815155\n",
      "0.63396975641\n",
      "0.608747437436\n",
      "0.707698419793\n",
      "0.665680049833\n",
      "0.667800689714\n",
      "0.665753558631\n",
      "0.733485996927\n",
      "0.691667472017\n",
      "0.6834898588\n",
      "0.70084242092\n",
      "0.659601583238\n",
      "0.613108654619\n",
      "0.690308456415\n",
      "0.665002307197\n",
      "0.658786658276\n",
      "0.659846927228\n",
      "0.619205389728\n"
     ]
    }
   ],
   "source": [
    "print \"fold \" + str(np.argmax(ndcg)) \n",
    "count=0\n",
    "for train_index, test_index in rs:\n",
    "    if (count==int(np.argmax(ndcg))):\n",
    "        print (len(reviews_features.ix[test_index]))\n",
    "        x=mhr.executeFromDf(reviews_features.ix[test_index])\n",
    "    count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MHR ndcg=0.680939584302\n"
     ]
    }
   ],
   "source": [
    "mhr_ndcg=calc_ndcg(x,'powerWithStar',5) \n",
    "print \"MHR ndcg=\"+str(mhr_ndcg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
